#!/usr/bin/env python3
"""
Script de fusion des r√©sultats Airbnb
Fusionne les donn√©es des annonces (Phase 1) avec les donn√©es des h√¥tes (Phase 2)
"""

import os
import csv
import glob
from pathlib import Path

def read_csv_safe(filepath):
    """Lit un CSV en g√©rant diff√©rents encodages"""
    encodings = ['utf-8-sig', 'utf-8', 'latin-1', 'cp1252']
    
    for encoding in encodings:
        try:
            with open(filepath, 'r', encoding=encoding, newline='') as f:
                reader = csv.DictReader(f)
                return list(reader)
        except (UnicodeDecodeError, Exception):
            continue
    
    print(f"‚ö†Ô∏è Impossible de lire {filepath}")
    return []

def merge_results():
    """Fusionne tous les r√©sultats Phase 1 et Phase 2"""
    
    print("üîó FUSION DES R√âSULTATS")
    print("=" * 60)
    
    # Cr√©er le dossier de sortie
    output_dir = Path("output_final")
    output_dir.mkdir(exist_ok=True)
    
    # Lire tous les fichiers Phase 1 (annonces)
    phase1_files = sorted(glob.glob("output_phase1/page_*_listings.csv"))
    print(f"\nüìÑ Phase 1 : {len(phase1_files)} fichier(s) trouv√©(s)")
    
    all_listings = []
    for f in phase1_files:
        data = read_csv_safe(f)
        print(f"  - {os.path.basename(f)}: {len(data)} annonce(s)")
        all_listings.extend(data)
    
    print(f"üìä Total annonces: {len(all_listings)}")
    
    # Lire tous les fichiers Phase 2 (h√¥tes)
    phase2_files = sorted(glob.glob("output_phase2/page_*_hosts.csv"))
    print(f"\nüë• Phase 2 : {len(phase2_files)} fichier(s) trouv√©(s)")
    
    all_hosts = []
    for f in phase2_files:
        data = read_csv_safe(f)
        print(f"  - {os.path.basename(f)}: {len(data)} h√¥te(s)")
        all_hosts.extend(data)
    
    print(f"üìä Total h√¥tes: {len(all_hosts)}")
    
    # Cr√©er un dictionnaire des h√¥tes index√© par URL
    hosts_dict = {}
    for host in all_hosts:
        url = host.get('url', '').strip()
        if url:
            hosts_dict[url] = host
    
    print(f"\nüîë Index des h√¥tes cr√©√©: {len(hosts_dict)} entr√©e(s) unique(s)")
    
    # Fusionner les donn√©es
    print("\nüîó Fusion en cours...")
    merged_data = []
    matched_count = 0
    
    for listing in all_listings:
        # Donn√©es de base de l'annonce
        merged_row = {
            'url_annonce': listing.get('url', ''),
            'titre': listing.get('title', ''),
            'licence': listing.get('license_code', ''),
            'host_url': listing.get('host_profile_url', ''),
            'host_name_from_listing': listing.get('host_name', ''),
            'host_rating_from_listing': listing.get('host_overall_rating', ''),
            'host_joined_from_listing': listing.get('host_joined', ''),
            'scraped_at': listing.get('scraped_at', ''),
        }
        
        # Chercher les infos d√©taill√©es de l'h√¥te
        host_url = listing.get('host_profile_url', '').strip()
        if host_url and host_url in hosts_dict:
            host_data = hosts_dict[host_url]
            merged_row.update({
                'host_name_detailed': host_data.get('name', ''),
                'host_rating_detailed': host_data.get('rating', ''),
                'host_joined_year': host_data.get('joined_year', ''),
                'host_years_active': host_data.get('years_active', ''),
                'host_listing_count': host_data.get('listing_count', ''),
                'host_scrape_notes': host_data.get('notes', ''),
            })
            matched_count += 1
        else:
            # H√¥te non trouv√© dans Phase 2
            merged_row.update({
                'host_name_detailed': '',
                'host_rating_detailed': '',
                'host_joined_year': '',
                'host_years_active': '',
                'host_listing_count': '',
                'host_scrape_notes': 'H√¥te non scrap√© en Phase 2',
            })
        
        merged_data.append(merged_row)
    
    print(f"‚úÖ Fusion termin√©e: {matched_count}/{len(all_listings)} annonces avec donn√©es h√¥te compl√®tes")
    
    # √âcrire le fichier final
    output_file = output_dir / "final_complete_results.csv"
    
    if merged_data:
        fieldnames = [
            'url_annonce',
            'titre',
            'licence',
            'host_url',
            'host_name_from_listing',
            'host_name_detailed',
            'host_rating_from_listing',
            'host_rating_detailed',
            'host_joined_from_listing',
            'host_joined_year',
            'host_years_active',
            'host_listing_count',
            'host_scrape_notes',
            'scraped_at',
        ]
        
        with open(output_file, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(merged_data)
        
        print(f"\n‚úÖ Fichier final cr√©√©: {output_file}")
        print(f"üìä Nombre total de lignes: {len(merged_data)}")
        
        # Statistiques
        complete_data = sum(1 for row in merged_data if row['host_name_detailed'])
        incomplete_data = len(merged_data) - complete_data
        
        print(f"\nüìà STATISTIQUES:")
        print(f"  - Donn√©es compl√®tes (Phase 1 + Phase 2): {complete_data}")
        print(f"  - Donn√©es partielles (Phase 1 uniquement): {incomplete_data}")
        
        if incomplete_data > 0:
            print(f"\n‚ö†Ô∏è {incomplete_data} annonce(s) n'ont pas de donn√©es h√¥te d√©taill√©es")
            print("   (H√¥tes possiblement d√©j√† scrap√©s dans une page pr√©c√©dente ou erreurs)")
    else:
        print("‚ùå Aucune donn√©e √† fusionner!")
    
    print("\n" + "=" * 60)
    print("‚úÖ FUSION TERMIN√âE")

if __name__ == "__main__":
    merge_results()
