# ğŸš€ Orchestrateur Airbnb - Guide Complet

## ğŸ“‹ Vue d'ensemble

Ce systÃ¨me automatise **complÃ¨tement** le scraping d'Airbnb en 2 phases :
1. **Phase 1** : Scraping des annonces (Python + Playwright)
2. **Phase 2** : Scraping des profils hÃ´tes (Node.js + Puppeteer)

**RÃ©sultat** : Un fichier CSV unifiÃ© avec toutes les donnÃ©es !

---

## ğŸ¯ Avantages

âœ… **Automatique** : Lancez et oubliez (4-6h d'exÃ©cution)  
âœ… **RÃ©silient** : Continue mÃªme si une page Ã©choue  
âœ… **Intelligent** : Ã‰vite les doublons d'hÃ´tes  
âœ… **Page par page** : Pas de timeout GitHub Actions  
âœ… **Complet** : Fusionne automatiquement toutes les donnÃ©es  

---

## ğŸ“‚ Structure des fichiers

```
votre-repo/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ scrape.yml              # Workflow Phase 1 (existant)
â”‚       â”œâ”€â”€ scrape-airbnb.yml       # Workflow Phase 2 (existant)
â”‚       â””â”€â”€ orchestrator.yml        # ğŸ†• Nouveau workflow orchestrateur
â”œâ”€â”€ scrape_airbnb.py                # Script Python (existant)
â”œâ”€â”€ scraper.js                      # Script Node.js (existant)
â”œâ”€â”€ requirements.txt                # (existant)
â”œâ”€â”€ package.json                    # (existant)
â”œâ”€â”€ merge_results.py                # ğŸ†• Script de fusion
â”œâ”€â”€ search_urls.txt                 # ğŸ†• Votre liste d'URLs
â””â”€â”€ README_ORCHESTRATOR.md          # ğŸ†• Cette documentation
```

---

## ğŸš€ Installation

### Ã‰tape 1 : Ajoutez les nouveaux fichiers

1. CrÃ©ez `.github/workflows/orchestrator.yml`
2. CrÃ©ez `merge_results.py` Ã  la racine
3. CrÃ©ez `search_urls.txt` Ã  la racine

### Ã‰tape 2 : Mettez Ã  jour `requirements.txt`

Ajoutez cette ligne si elle n'existe pas :
```
pandas>=2.0.0
```

### Ã‰tape 3 : Committez et pushez

```bash
git add .
git commit -m "Ajout orchestrateur automatique"
git push
```

---

## ğŸ“ Utilisation

### 1ï¸âƒ£ PrÃ©parez vos URLs

Ã‰ditez le fichier `search_urls.txt` et ajoutez vos URLs de pages de recherche :

```
https://www.airbnb.com/s/Dubai/homes
https://www.airbnb.com/s/Dubai/homes?items_offset=18
https://www.airbnb.com/s/Dubai/homes?items_offset=36
...
```

**ğŸ’¡ Astuce** : Pour obtenir les URLs des pages 2, 3, 4... :
- Allez sur Airbnb
- Faites votre recherche
- Cliquez sur "Page 2", copiez l'URL
- RÃ©pÃ©tez pour les pages suivantes

### 2ï¸âƒ£ Lancez l'orchestrateur

1. Allez sur GitHub â†’ Votre repo
2. Cliquez sur **Actions**
3. SÃ©lectionnez **"Orchestrateur Airbnb Complet"**
4. Cliquez sur **"Run workflow"**
5. Cliquez sur **"Run workflow"** (confirmation)

### 3ï¸âƒ£ Partez dormir ğŸ’¤

Le workflow va :
- Traiter chaque page l'une aprÃ¨s l'autre
- Scraper les annonces (Phase 1)
- Scraper les profils hÃ´tes (Phase 2)
- Fusionner automatiquement les rÃ©sultats

**DurÃ©e estimÃ©e** : ~30-45 minutes par page  
**DurÃ©e totale (8 pages)** : ~4-6 heures

### 4ï¸âƒ£ TÃ©lÃ©chargez les rÃ©sultats

Une fois terminÃ© :
1. Allez dans l'onglet **Actions**
2. Cliquez sur votre run terminÃ©
3. Scrollez en bas vers **"Artifacts"**
4. TÃ©lÃ©chargez **"final-complete-results"** ğŸ‰

---

## ğŸ“Š Format du CSV final

Le fichier `final_complete_results.csv` contient :

| Colonne | Description | Source |
|---------|-------------|--------|
| `url_annonce` | URL de l'annonce | Phase 1 |
| `titre` | Titre de l'annonce | Phase 1 |
| `licence` | Code de licence | Phase 1 |
| `host_url` | URL du profil hÃ´te | Phase 1 |
| `host_name_from_listing` | Nom hÃ´te (depuis annonce) | Phase 1 |
| `host_name_detailed` | Nom hÃ´te (depuis profil) | Phase 2 |
| `host_rating_from_listing` | Rating (depuis annonce) | Phase 1 |
| `host_rating_detailed` | Rating (depuis profil) | Phase 2 |
| `host_joined_from_listing` | AnnÃ©e inscription (annonce) | Phase 1 |
| `host_joined_year` | AnnÃ©e inscription (profil) | Phase 2 |
| `host_years_active` | AnnÃ©es d'activitÃ© | Phase 2 |
| `host_listing_count` | Nombre d'annonces | Phase 2 |
| `host_scrape_notes` | Notes/erreurs | Phase 2 |
| `scraped_at` | Date du scraping | Phase 1 |

**ğŸ’¡ Pourquoi des colonnes en double ?**  
Parce que Phase 1 et Phase 2 utilisent des mÃ©thodes diffÃ©rentes. Vous avez ainsi les deux versions pour vÃ©rifier la cohÃ©rence !

---

## ğŸ” Gestion des doublons

Le systÃ¨me est **intelligent** :
- Si un hÃ´te apparaÃ®t sur plusieurs pages, il est scrapÃ© **une seule fois**
- Ã‰conomise du temps et Ã©vite les blocages Airbnb

---

## âš ï¸ Gestion des erreurs

### Si une page Ã©choue :
âœ… Le workflow **continue** avec les pages suivantes  
âœ… Vous obtenez les rÃ©sultats des pages qui ont rÃ©ussi  
âœ… Les erreurs sont loggÃ©es dans les artifacts "debug-info"

### Si Phase 1 Ã©choue pour une page :
- Phase 2 est **sautÃ©e** pour cette page
- Le workflow continue avec la page suivante

### Si Phase 2 Ã©choue pour une page :
- Les donnÃ©es Phase 1 sont **conservÃ©es**
- Le CSV final contiendra ces annonces (sans dÃ©tails hÃ´tes)
- Le workflow continue avec la page suivante

---

## ğŸ› Debugging

Si vous avez des problÃ¨mes :

1. **TÃ©lÃ©chargez les artifacts de debug**
   - `phase1-listings` : RÃ©sultats Phase 1 par page
   - `phase2-hosts` : RÃ©sultats Phase 2 par page
   - `debug-info` : Logs et informations dÃ©taillÃ©es

2. **VÃ©rifiez les logs du workflow**
   - Allez dans Actions â†’ Votre run
   - Cliquez sur "orchestrate"
   - Regardez les logs dÃ©taillÃ©s

3. **Testez individuellement**
   - Testez d'abord "Airbnb Scrape" (Phase 1)
   - Puis "Scrape Airbnb Hosts" (Phase 2)
   - Si les deux fonctionnent, l'orchestrateur fonctionnera !

---

## ğŸ”§ Personnalisation

### Modifier le nombre max d'annonces par page

Dans `orchestrator.yml`, ligne ~60 :
```yaml
export MAX_LISTINGS="20"  # Changez cette valeur
```

### Modifier la durÃ©e max par page

Dans `orchestrator.yml`, ligne ~61 :
```yaml
export MAX_MINUTES="15"  # Changez cette valeur (en minutes)
```

### Ajouter un dÃ©lai entre les pages

Dans `orchestrator.yml`, ligne ~184 :
```bash
sleep 10  # Changez cette valeur (en secondes)
```

---

## ğŸ“ˆ Statistiques

Ã€ la fin de l'exÃ©cution, vous verrez :
```
ğŸ“Š RÃ‰SUMÃ‰ DES RÃ‰SULTATS
======================================
Phase 1 (annonces): 8 fichiers
Phase 2 (hÃ´tes): 8 fichiers
RÃ©sultat final: 144 lignes de donnÃ©es
âœ… Fichier: output_final/final_complete_results.csv
```

---

## â“ FAQ

### Q : Puis-je scraper plus de 8 pages ?
**R :** Oui ! Ajoutez simplement plus d'URLs dans `search_urls.txt`. Attention au timeout de 7h max.

### Q : Puis-je scraper plusieurs villes en mÃªme temps ?
**R :** Oui ! Mettez toutes les URLs (toutes villes) dans `search_urls.txt`.

### Q : Le workflow est trop long, que faire ?
**R :** RÃ©duisez le nombre de pages, ou lancez plusieurs runs sÃ©parÃ©s avec diffÃ©rents `search_urls.txt`.

### Q : Je veux garder mes anciens workflows, c'est possible ?
**R :** Oui ! L'orchestrateur utilise vos workflows existants. Vous pouvez toujours les lancer manuellement.

### Q : Les donnÃ©es sont-elles dedupliquÃ©es ?
**R :** Les **hÃ´tes** sont dedupliquÃ©s (scrapÃ©s une seule fois). Les **annonces** ne sont pas dedupliquÃ©es (normal, chaque page peut avoir des annonces diffÃ©rentes).

---

## ğŸ‰ C'est tout !

Vous avez maintenant un systÃ¨me **100% automatique** pour scraper Airbnb !

**Workflow :**
1. CrÃ©ez `search_urls.txt`
2. Lancez l'orchestrateur
3. Partez dormir
4. TÃ©lÃ©chargez le CSV final

**Profitez ! ğŸš€**

---

## ğŸ“ Support

Si vous avez des questions ou des problÃ¨mes, vÃ©rifiez :
1. Les logs du workflow dans GitHub Actions
2. Les artifacts de debug
3. Que vos URLs dans `search_urls.txt` sont valides

---

**Fait avec â¤ï¸ pour automatiser votre scraping Airbnb**
