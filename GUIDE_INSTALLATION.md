# ğŸš€ GUIDE D'INSTALLATION RAPIDE - Orchestrateur Airbnb

## âœ… Fichiers crÃ©Ã©s pour vous

J'ai crÃ©Ã© 4 fichiers essentiels :

1. **`.github_workflows_orchestrator.yml`** â†’ Ã€ renommer et placer dans `.github/workflows/`
2. **`merge_results.py`** â†’ Ã€ placer Ã  la racine de votre repo
3. **`search_urls.txt`** â†’ Ã€ placer Ã  la racine de votre repo (et Ã  personnaliser)
4. **`README_ORCHESTRATOR.md`** â†’ Documentation complÃ¨te

---

## ğŸ“¥ INSTALLATION EN 5 Ã‰TAPES

### Ã‰tape 1 : TÃ©lÃ©chargez les fichiers
TÃ©lÃ©chargez tous les fichiers que je viens de crÃ©er.

### Ã‰tape 2 : Placez les fichiers dans votre repo GitHub

```
votre-repo/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ scrape.yml                    â† (existant)
â”‚       â”œâ”€â”€ scrape-airbnb.yml             â† (existant)
â”‚       â””â”€â”€ orchestrator.yml              â† ğŸ†• RENOMMEZ et placez ici
â”œâ”€â”€ scrape_airbnb.py                      â† (existant)
â”œâ”€â”€ scraper.js                            â† (existant)
â”œâ”€â”€ merge_results.py                      â† ğŸ†• Placez Ã  la racine
â”œâ”€â”€ search_urls.txt                       â† ğŸ†• Placez Ã  la racine
â””â”€â”€ README_ORCHESTRATOR.md                â† ğŸ†• Placez Ã  la racine
```

**IMPORTANT** : Renommez `.github_workflows_orchestrator.yml` en `orchestrator.yml`

### Ã‰tape 3 : Mettez Ã  jour requirements.txt

Ouvrez votre fichier `requirements.txt` et ajoutez cette ligne (si elle n'existe pas) :
```
pandas>=2.0.0
```

### Ã‰tape 4 : Personnalisez search_urls.txt

Ã‰ditez `search_urls.txt` et remplacez les URLs d'exemple par VOS URLs de recherche Airbnb.

**Exemple :**
```
https://www.airbnb.com/s/Paris/homes
https://www.airbnb.com/s/Paris/homes?items_offset=18
https://www.airbnb.com/s/Paris/homes?items_offset=36
...
```

ğŸ’¡ **Comment obtenir les URLs des pages 2, 3, 4... ?**
1. Allez sur Airbnb
2. Faites votre recherche
3. Cliquez sur "Page suivante"
4. Copiez l'URL de la barre d'adresse
5. RÃ©pÃ©tez pour chaque page

### Ã‰tape 5 : Committez et pushez

```bash
git add .
git commit -m "Ajout orchestrateur automatique"
git push
```

---

## ğŸ¯ UTILISATION

### 1. Lancez le workflow

1. Allez sur **GitHub** â†’ Votre repo â†’ **Actions**
2. Cliquez sur **"Orchestrateur Airbnb Complet"**
3. Cliquez sur **"Run workflow"** (bouton vert)
4. Confirmez en cliquant Ã  nouveau sur **"Run workflow"**

### 2. Attendez (4-6 heures pour 8 pages)

Le systÃ¨me va automatiquement :
- âœ… Scraper chaque page d'annonces (Phase 1)
- âœ… Extraire les URLs des hÃ´tes
- âœ… Scraper les profils des hÃ´tes (Phase 2)
- âœ… Fusionner toutes les donnÃ©es
- âœ… CrÃ©er le CSV final

### 3. TÃ©lÃ©chargez les rÃ©sultats

Une fois terminÃ© :
1. Allez dans **Actions** â†’ Cliquez sur votre run terminÃ©
2. Scrollez en bas vers **"Artifacts"**
3. TÃ©lÃ©chargez **"final-complete-results"** ğŸ‰

Le fichier `final_complete_results.csv` contient TOUTES vos donnÃ©es fusionnÃ©es !

---

## ğŸ“Š CE QUE VOUS OBTENEZ

Un fichier CSV avec :
- URLs et titres des annonces
- Codes de licence
- Informations complÃ¨tes sur chaque hÃ´te :
  - Nom
  - Rating
  - AnnÃ©e d'inscription
  - AnnÃ©es d'activitÃ©
  - Nombre d'annonces
  - Et plus !

**Tout est fusionnÃ© intelligemment pour vous ! ğŸ‰**

---

## ğŸ” AVANTAGES DU SYSTÃˆME

âœ… **100% automatique** - Lancez et oubliez  
âœ… **RÃ©silient** - Continue mÃªme si une page Ã©choue  
âœ… **Intelligent** - Ã‰vite les doublons d'hÃ´tes  
âœ… **SÃ©curisÃ©** - Pas de timeout GitHub (page par page)  
âœ… **Complet** - Fusionne automatiquement Phase 1 + Phase 2  
âœ… **Non-invasif** - Vos scrapers existants restent intacts  

---

## âš ï¸ POINTS IMPORTANTS

1. **Vos scrapers existants ne sont PAS modifiÃ©s**
   - `scrape.yml` reste identique
   - `scrape-airbnb.yml` reste identique
   - L'orchestrateur les utilise tels quels

2. **Gestion intelligente des doublons**
   - Si un hÃ´te apparaÃ®t sur plusieurs pages, il est scrapÃ© UNE SEULE FOIS
   - Ã‰conomise du temps et Ã©vite les blocages

3. **Gestion des erreurs**
   - Si une page Ã©choue, le systÃ¨me continue avec les suivantes
   - Vous obtenez toujours un rÃ©sultat final avec les pages qui ont rÃ©ussi

4. **DurÃ©e d'exÃ©cution**
   - ~30-45 minutes par page
   - ~4-6 heures pour 8 pages
   - Bien en dessous de la limite GitHub de 7h

---

## ğŸ†˜ BESOIN D'AIDE ?

Consultez le fichier `README_ORCHESTRATOR.md` pour :
- Documentation complÃ¨te
- FAQ
- Guide de debugging
- Personnalisation avancÃ©e

---

## ğŸ‰ C'EST TOUT !

Vous avez maintenant un systÃ¨me d'orchestration automatique qui :
1. Prend vos URLs de pages
2. Scrappe tout automatiquement (Phase 1 + Phase 2)
3. Fusionne les rÃ©sultats
4. Vous livre un CSV complet

**Plus besoin de copier-coller manuellement ! ğŸš€**

---

**Bon scraping ! ğŸ’ª**
